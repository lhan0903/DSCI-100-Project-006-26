{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 006-26 Project Report\n",
    ">Linda Han, Shaqed Orr, Eric Zhang, Prabhjot Singh\n",
    "\n",
    "## Introduction:\n",
    "The Iris flower got its name from the goddess of rainbows in Acient Greek mythology, and similar to a rainbow it can be found in diverse colours, shapes and sizes. Despite having over 250 species, we are only interested in 3 specific classes of these perennial plants in our project: Versicolor, Setosa, and Virginica.\n",
    "\n",
    "In this report, we try to answer the question: given an Iris flower belonging to one of these three classes, how do we predict which class they are in? \n",
    "\n",
    "We will be using the `Iris` data set found on https://archive.ics.uci.edu/ml/datasets/iris to build a classifier.\n",
    "\n",
    "This data set contains 150 samples of data with 3 different classes. Each class contains 50 samples, and four features: sepal length, sepal width, petal length, and petal width. Ultimately, we are trying to predict the class of Iris flowers by these four distinct features using the K-Nearest Neighbor classification method. \n",
    "\n",
    "<img src=\"https://www.almanac.com/sites/default/files/styles/landscape/public/image_nodes/iris-flowers.jpg?itok=yVwKlyWK\" width=\"400\" height=\"200\">\n",
    "\n",
    "*Source: https://www.almanac.com/plant/irises*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary data analysis:\n",
    "---\n",
    "\n",
    "First, we load in all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(ggplot2)\n",
    "\n",
    "options(repr.matrix.max.rows = 6) # this lists only 6 rows when we try to display the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and cleaning the data\n",
    "\n",
    "1) We read the `iris` dataset from the original source on the web (UCI Machine Learning Repository) using `read_csv` function\n",
    "\n",
    "2) We added column names to reflect each of the attributes and mutated the `class` column such that it becomes a factor using `as_factor()`. \n",
    "\n",
    "We can now say that our dataset is **tidy** as there is a single iris observation on every row, each column is a single variable (either a measurement of the iris flower or the class it belongs to), and each cell holds a single value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_col <- c(\"sepal_length_cm\", \"sepal_width_cm\", \"petal_length_cm\", \"petal_width_cm\", \"class\")\n",
    "iris <- read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", col_names= iris_col) %>% \n",
    "        mutate(class = as_factor(class))\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure the reproducibility of our results, we use the `set.seed()` function with a randomly chosen initial value. \n",
    "\n",
    "There are 150 observations in total and we see from `table 0.1` below that there are 50 observations from each iris class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes the number of observations in each class \n",
    "# (Iris-setosa, Iris-versicolor, or Iris-virginica)\n",
    "count <- iris %>%\n",
    "        count(class)\n",
    "\n",
    "'Table 0.1'\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to have enough training data points for building an accurate classifier and enough testing data points for making an accurate assessment of the model's performance. Since the proportion of each class is equally represented and the data size isn't large, we choose to partition the data into a 80% training and 20% testing set. This gives us 123 data points for training and 27 data points for testing, which seems like a reasonable partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(777)\n",
    "\n",
    "iris_split <- initial_split(iris, prop = 0.80, strata = class)\n",
    "iris_train <- training(iris_split)\n",
    "iris_test <- testing(iris_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Summary of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only the training data, we summarize the data into 2 tables and count the number of rows with missing values to check that all of our rows have values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A summary of the average value of each column using `summarize()` and `across()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_avg_size <- iris_train %>%\n",
    "        summarize(across(sepal_length_cm:petal_width_cm, mean))\n",
    "\n",
    "'Table 1.1'\n",
    "iris_avg_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "2. A summary of the number of observations in each class (Iris-setosa, Iris-versicolor, or Iris-virginica). We observe from this summary that each class has an equal number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_class_count <- iris_train %>%\n",
    "        count(class)\n",
    "\n",
    "'Table 1.2'\n",
    "iris_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "3. The count for the number of missing rows shows us that all rows in the training dataset have values and will all make meaningful contribution to the building of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(iris_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Visualization of the training data\n",
    "\n",
    "Using only training data, we conduct an exploratory data analysis by visualizing the data with two scatterplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first graph, we use `ggplot()` to plot the predictors `sepal_width_cm` on the y-axis against `sepal_length_cm` on the x-axis. We also set `colour = \"Class\"` to mark each observation according to their class. We chose this pair of predictors as their name suggests that they are both measurements of the flower sepal and could therefore be correlated.\n",
    "\n",
    "To improve readability, we also use the `options()` and `theme()` functions to modify the size of the plot and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 1\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "iris_plot_sepal <- ggplot(data = iris_train, \n",
    "                          aes(x = sepal_length_cm, y = sepal_width_cm , colour = class )) +\n",
    "                geom_point() +\n",
    "                labs(x = \"Sepal length (cm)\", y = \"Sepal width (cm)\",\n",
    "                     colour = \"Class\", caption = \"Figure 1.1\") +\n",
    "                ggtitle(\"Sepal Width vs Sepal Length\") +\n",
    "                theme(text = element_text(size = 20))\n",
    "\n",
    "iris_plot_sepal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see the red data points that represent the `Iris-setosa` class form a distinct cluster. Compared to data points from the `Iris-versicolor` and `Iris-virginica` class, the graph suggests that Iris Setosas generally have shorter sepal lengths and longer sepal widths. Meanwhile, the data points for `Iris-versicolor` and `Iris-virginica` seem to be blended together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "For the second graph, we repeat the same things we did for graph 1 except for changing the two predictors to `petal_length_cm` and `petal_width_cm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 2\n",
    "iris_plot_petal <- ggplot(data = iris_train,\n",
    "                          aes(x = petal_length_cm, y = petal_width_cm , colour = class )) +\n",
    "                    geom_point() +\n",
    "                    labs(x = \"Petal length (cm)\", y = \"Petal width (cm)\",\n",
    "                         colour = \"Class\", caption = \"Figure 1.2\") +\n",
    "                    ggtitle(\"Petal Width vs Petal Length\") +\n",
    "                    theme(text = element_text(size = 20))\n",
    "\n",
    "iris_plot_petal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the colors, we observe 3 regions and their distinctiveness suggest that we can classify irises based on their petal length and petal width.\n",
    "\n",
    "Petal width (in ascending order): `Iris-setosa` < `Iris-versicolor` < `Iris-virginica`\n",
    "\n",
    "Petal length (in ascending order): `Iris-setosa` < `Iris-versicolor` < `Iris-virginica`\n",
    "\n",
    "From the ranking above, we can see that `Iris-setosa` has the shortest petal width and length, `Iris-virginica` has the longest petal width and length, and `Iris-versicolor` tends to be somewhere in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Phase (Building The K-Nearest Neighbour Classifier)\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Recipe \n",
    "\n",
    "We choose to use all non-categorical variables as predictors since all of them depict crucial measurements of the iris flower.\n",
    "\n",
    "Since the K-nearest neighbors algorithm is sensitive to the scale of the predictors, we use `step_center()` and `step_scale()` with the `all_predictors()` argument passed in to standardize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_recipe <- recipe(class ~ ., data = iris_train) %>% \n",
    "            step_center(all_predictors()) %>% \n",
    "            step_scale(all_predictors()) \n",
    "\n",
    "iris_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "To visualize the scaled `iris_train` data, we use the `prep()` and `bake()` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scaled <- iris_recipe %>% \n",
    "                prep() %>% \n",
    "                bake(iris_train)\n",
    "\n",
    "'Figure 1.3'\n",
    "iris_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2. Model Specification\n",
    "\n",
    "Now we create a nearest neighbour model for our training set using `nearest_neighbor()` and setting the neighbors argument to `tune()` so we can proceed to find the optimal $K$ value. \n",
    "\n",
    "As this is a KNN classification problem, we set the engine to `\"kknn\"` and the mode to `\"classification\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% \n",
    "            set_engine(\"kknn\") %>% \n",
    "            set_mode(\"classification\")\n",
    "\n",
    "iris_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3. Vfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to choosing the number of folds for performing cross-validation, we need to take into account that having too few folds (such as 1,2) could result in a biased estimation of our model performance. On the other hand, having too many folds (such as 20) could increase the runtime and cause the overall process to be computationally expensive. Taking that into consideration, choosing $K = 5$ folds seems to be reasonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_vfold <- vfold_cv(iris_train, v = 5, strata = class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4. Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a workflow and use the `tune_grid()` function to try $K$ values from 1 to 20 by passing in a tibble object that we created called `k_vals`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals <- tibble(neighbors = seq(from=1, to=20, by=1))\n",
    "\n",
    "iris_tune_workflow <- workflow() %>% \n",
    "    add_recipe(iris_recipe) %>% \n",
    "    add_model(iris_spec) %>% \n",
    "    tune_grid(resamples = iris_vfold, grid = k_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 5. Collect Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `iris_tune_workflow`, we use the `collect_metrics()` function and filter for `accuracy` from the `.metric` column. However, this gives us a table of unordered rows. To select the `neighbors` value that gives us the highest accuracy, we use `arrange()` with `desc()` to arrange the rows by their `mean` column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_metrics_tune <- iris_tune_workflow %>% \n",
    "    collect_metrics() %>% \n",
    "    filter(.metric == \"accuracy\") %>% \n",
    "    arrange(desc(mean))\n",
    "\n",
    "'Figure 5.1'\n",
    "iris_metrics_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the first three rows of Figure 5.1 above that $K = 7,8,9$ all yield the highest accuracy of 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 6. Plot Neighbors vs Accuracy Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize Figure 5.1, we create a scatterplot with `neighbors` on the x-axis and `mean` on the y-axis. The `geom_line()` function connects all the points with lines and the `scale_x_continuous()` is used to to adjust the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_plot <- ggplot(iris_metrics_tune, aes(x=neighbors, y=mean)) + \n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x = \"Neighbors\", y = \"Accuracy Estimate\", caption=\"Figure 6.1\") + \n",
    "    ggtitle(\"Accuracy vs K\") +\n",
    "    theme(text = element_text(size = 20)) +\n",
    "    scale_x_continuous(breaks = seq(0, 25, by = 2))\n",
    "\n",
    "neighbors_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our model to have the right amount of sensitivity and avoid under or overfitting. From Figure 6.1 above, we see that the accuracy estimate peaks from $K=7$ neighbors to $K=14$ neighbors. Therefore, **We choose the optimal $K$ to be $7$** as it is the point where the accuracy estimate first peaked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 7. Rebuild Model Specification and Workflow with $K$ = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the optimal $K$ found, we rebuild the model with the `neighbors` argument equal to $7$ and name it `iris_spec_optimal`. We also create a new workflow object called `iris_fit` that uses the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_spec_optimal <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 7) %>% \n",
    "            set_engine(\"kknn\") %>% \n",
    "            set_mode(\"classification\")\n",
    "\n",
    "iris_spec_optimal\n",
    "\n",
    "iris_fit <- workflow() %>% \n",
    "    add_recipe(iris_recipe) %>% \n",
    "    add_model(iris_spec_optimal) %>% \n",
    "    fit(iris_train)\n",
    "\n",
    "iris_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### Model Testing Phase\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the classifier to predict labels for our test dataset by using the `predict()` function and `bind_cols()` to bind the predicted class onto the test dataset for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_test_predictions <- predict(iris_fit, iris_test) %>% \n",
    "    bind_cols(iris_test)\n",
    "\n",
    "iris_test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Assess accuracy of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use `metrics` to check the accuracy of our predictions for the iris labels in the test set. We see that we have achieved 96% accuracy, which is the same as the accuracy estimate for our optimal $K=7$ model during training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_metrics_final <- iris_test_predictions %>% \n",
    "    metrics(truth = class, estimate = .pred_class)\n",
    "\n",
    "iris_metrics_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can also summarize the prediction outcomes by using a confusion matrix. By looking at the values in the matrix, we are given more detail about the reason for our 96% accuracy as we see that one `Iris-virginica` is mislabeled as an `Iris-versicolor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_conf_mat <- iris_test_predictions %>% \n",
    "    conf_mat(truth = class, estimate = .pred_class)\n",
    "\n",
    "iris_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3. Visualization of Data Analysis Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a mosaic plot ... TODO ... add more comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data<- iris_test_predictions %>%\n",
    "    semi_join(iris_test) %>%\n",
    "    group_by(class, .pred_class)%>%\n",
    "    summarize(n=n())\n",
    "\n",
    "mos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_plot <- ggplot(mos_data, aes(x=class, y=n, fill=.pred_class))+\n",
    "        geom_bar(position=\"fill\", stat=\"identity\")+\n",
    "        labs(x=\"Classes of Iris Flower\", y=\"Count\",\n",
    "             fill=\"Iris Classes\", caption=\"Figure 2.3\") +\n",
    "        ggtitle(\"Predictions of Iris Flowers\") +\n",
    "        theme(text = element_text(size = 15))\n",
    "\n",
    "mos_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A summary of our findings:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
